# 동영상의 품질을 결정하는 요소

## 초당 프레임수 (FPS)
영상 안에서 한장 한장의 이미지를 프레임이라고 부릅니다. 즉 초당 프레임수는 일초 동안 재생되는 이미지의 수를 말합니다. 아주 오래전에 영화 업계에서는 초당 24프레임 즉 24fps를 표준으로 삼았고, TV는 미국 표준(NTSC)은 30fps를 그리고 유럽 표준(PAL)은 25fps를 표준으로 삼아 왔습니다. 왜 이렇게 국가별로, 산업별로 표준 FPS가 다른지는 기술적인 이유와 비용적인 이유가 있었는데, 그것은 다음에 자세히 다루어 보겠습니다. 그리고 지금 인터넷으로 볼 수 있는 많은 디지털 동영상은 30fps가 대부분이고 60fps도 많이 만들어지고 있습니다. 그리고 60fps가 넘어서면 인간의 눈으로는 그 차이를 인지하지 못한다고 합니다. 즉 60fps면 가장 좋은 FPS를 가지게 되는 것이고 24fps면 볼만한 동영상, 그리고 이것보다 떨어지면 “동영상이 많이 끊긴다, 부자연스럽다” 라고 느껴질 것입니다. 한가지 집고 넘어가야 할 사실은, 30fps로 찍은 영상을 60fps로 인코딩한다고 해서 더 부드러워지지 않는다는 점 입니다. 원본이 30fps인것을 억지로 60fps로 바꾼다고 해도 같은 영상이 2장씩 들어가는 것이기 때문입니다.

```
raspivid
--framerate,    -fps        Specify the frames per second to record
프레임 비율은 최소 2fps, 최대 30fps까지 허용됩니다. 이것은 앞으로 변경될 수 있습니다.
```

## 해상도
해상도는 같은 크기의 화면에 표현할 수 있는 픽셀의 수를 말합니다. </br>
픽셀(화소)이란 화면을 구성하는 가장 작은 단위로 “하나의 점”이라고 생각하시면 됩니다. 해상도가 높다는 것은 같은 이미지를 더 많은 픽셀(화소)로 표현 했다는 것입니다. </br>
카메라 성능의 이야기 할 때 500만화소, 1000만 화소 등도 같은 의미입니다. 해상도는 (가로 픽셀수) X (세로 픽셀수)로 표현하기도 하고 SD급, HD급, Full HD(FHD)급, Ultra HD(UHD)급이라고 표현하기도 합니다. 이름이 붙어있는 SD, HD 와 같은 해상도는 가장 많이 사용되는 표준 해상도를 표현하는 방식입니다.

* SD (Standard Definition) : 720 x 480
* HD (High Definition): 1280 x 720
* Full HD : 1920 x 1080
* Ultra HD : 4096 x 2160

## 주사 방식, 인터레이스(Interace), 프로그레시브(Progressive)
720p, 1080p, 1080i 라고 표현하는 방식이 있습니다. 720p는 HD 즉 1280 X 720을 말하는 것이고, 1080p나 1080i는 Full HD 즉 1920 x 1080을 말하는 것입니다. 그런데 여기서 뒤에 붙은 p나 i는 무엇을 말하는 것 일까요? 이것은 바로 이미지를 화면에 뿌려주는 방식을 말합니다. 그럼 p와 i는 어떤 차이가 있는지 살펴보겠습니다. i는 Interlace를 의미하며 2장의 이미지로 하나의 화면을 구성하는 방식입니다.

## 비트레이트
비트레이트는 Bits Per Second(bps)로 표기하며, 1초의 동영상을 구성하는 데이터의 크기를 나타냅니다.</br>
이것은 동영상을 얼마나 정밀하게 표현하는가 또는 얼마나 화면을 뭉개지 않고 압축하는가라고 이해하면 됩니다.  </br>
초당 1메가로 표현할 수 있는 동영상과 초당 10메가로 표현할 수 있는 동영상의 품질은 당연히 큰 차이가 날 수밖에 없기 때문에 비트레이트는 동영상의 화질을 구성하는 매우 중요한 요소입니다.  </br>
10Mbps로 구성된 영상을 1Mbps로 인코딩하면 당연히 화면이 뭉개지고 화질이 떨어질 것입니다. </br>
하지만 1Mbps로 구성된 영상을 10Mbps로 인코딩한다고 해서 화질이 좋아지지는 않습니다. </br>
동영상을 처음 촬영할때의 그 원본 보다 좋아질수는 없습니다. 역시 비트레이트 또한 원본이 중요합니다.

# 영상처리와 비디오 압축 모델

###블록 단위 움직임 보상 기반의 영상 압축 표준인 H.264 또는 MPEG-4 파트 10, Advanced Video Coding (MPEG-4 AVC)는 동영상 녹화, 압축, 배포를 위한 방식들 중 현재 가장 보편적으로 사용되고 있는 포맷이다.


## MPEG-1

## MPEG-2

## MPEG-3

## H.264
H.264는 4x4 또는 16x16 블록 중 하나를 수행 방향에 따라 예측을 위해 여러 방향 모드까지 허용하는 변환하기 전에 내 코드 블록에 대한 인트라 예측을 수행한다.


## H.264 AVC vs H.265 HEVC
1. 압축의 기본 단위라고 할 수 있는 기존의 매크로블럭이 CTU(Coding Tree Unit)로 대체
2. H.264/AVC 표준에서는 CABAC과 CAVLC의 두 가지 엔트로피 코딩을 사용했지만 H.265/HEVC에서는 CABAC만을 사용
    (다만 복잡성을 가지지 않는 단조로운 영상의 경우에는 CAVLC를 이용하기도 함)
3. 인트라 예측에는 33개의 예측 모드와 DC, Planar 모드를 합해서 총 35가지의 모드가 가능
4. 인터 예측에는 Qpel 단위에서 7탭, 8탭 필터를 사용했습니다. 예측에 사용되는 블럭의 크기는 최소 4x4 부터 64x64 까지 가능
5. 움직임 벡터 예측에는 AMVP와 merge 모드를 사용
6. 주파수 변환의 블럭 사이즈는 H.264/AVC의 4x4, 8x8에서 16x16, 32x32가 추가
7. 기존의 In-loop Deblocking 필터와 더불어 픽셀 단위의 오프셋을 추가해주는 SAO 필터가 적용
